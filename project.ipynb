{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, RobustScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import stdev\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing data**\n",
    "\n",
    "From the database, we've selected columns describing the time (year, date, time of day) of discovery and containment, the size and size class of the fires, location (described by latitude and longitude, state) as well as the owner of the land where the fire originated.\n",
    "\n",
    "\n",
    "Detailed column descriptions:\n",
    "\n",
    "FIRE_YEAR = Calendar year in which the fire was discovered or confirmed to exist.\n",
    "\n",
    "DISCOVERY_DATE = Date on which the fire was discovered or confirmed to exist.\n",
    "\n",
    "DISCOVERY_DOY = Day of year on which the fire was discovered or confirmed to exist.\n",
    "\n",
    "DISCOVERY_TIME = Time of day that the fire was discovered or confirmed to exist.\n",
    "\n",
    "STAT_CAUSE_DESCR = Description of the (statistical) cause of the fire.\n",
    "\n",
    "CONT_DATE = Date on which the fire was declared contained or otherwise controlled (mm/dd/yyyy where mm=month, dd=day, and yyyy=year).\n",
    "\n",
    "CONT_DOY = Day of year on which the fire was declared contained or otherwise controlled.\n",
    "\n",
    "CONT_TIME = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n",
    "\n",
    "FIRE_SIZE = Estimate of acres within the final perimeter of the fire.\n",
    "\n",
    "FIRE_SIZE_CLASS = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
    "\n",
    "LATITUDE = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
    "\n",
    "LONGITUDE = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
    "\n",
    "OWNER_DESCR = Name of primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
    "\n",
    "STATE = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect = sqlite3.connect('FPA_FOD_20170508.sqlite')\n",
    "data = pd.read_sql_query(\"SELECT FIRE_YEAR, DISCOVERY_DATE, DISCOVERY_DOY, DISCOVERY_TIME, STAT_CAUSE_DESCR, CONT_DATE, CONT_DOY, CONT_TIME, FIRE_SIZE, FIRE_SIZE_CLASS, LATITUDE, LONGITUDE, OWNER_DESCR, STATE FROM 'Fires'\", connect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = pd.to_datetime(0, unit='s').to_julian_date()\n",
    "#Convert discovery date from julian to standard date\n",
    "data['DISCOVERY_DATE'] = pd.to_datetime((data['DISCOVERY_DATE'] - epoch), unit='D', errors = 'ignore')\n",
    "#Convert containment date from julian to standard date\n",
    "data['CONT_DATE'] = pd.to_datetime((data['CONT_DATE'] - epoch), unit='D', errors = 'ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what we've imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DISCOVERY_MONTH'] = pd.DatetimeIndex(data['DISCOVERY_DATE']).month\n",
    "data['DISCOVERY_DAY_OF_WEEK'] = data['DISCOVERY_DATE'].dt.weekday_name\n",
    "data['CONT_MONTH'] = pd.DatetimeIndex(data['CONT_DATE']).month\n",
    "data['CONT_DAY_OF_WEEK'] = data['CONT_DATE'].dt.weekday_name\n",
    "\n",
    "data['DISCOVERY_DATE_COMPLETE'] = pd.to_datetime(data.DISCOVERY_DATE.astype('str') + ' ' + data.DISCOVERY_TIME, errors='coerce')\n",
    "data['CONT_DATE_COMPLETE'] = pd.to_datetime(data.CONT_DATE.astype('str') + ' ' + data.CONT_TIME, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapsing the containment and discovery time differences to the single feature 'duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DURATION_MINUTES'] = (data.CONT_DATE_COMPLETE - data.DISCOVERY_DATE_COMPLETE).astype('timedelta64[m]')\n",
    "\n",
    "#Dropping unneeded columns\n",
    "data.drop(['DISCOVERY_DATE', 'CONT_DATE', 'CONT_TIME', 'CONT_DOY', 'CONT_MONTH', 'CONT_DAY_OF_WEEK'], axis=1, inplace=True)\n",
    "data.drop(['DISCOVERY_DATE_COMPLETE', 'CONT_DATE_COMPLETE'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.FIRE_YEAR = data.FIRE_YEAR.astype(float)\n",
    "data.DISCOVERY_DOY = data.DISCOVERY_DOY.astype(float)\n",
    "data.DISCOVERY_TIME = data.DISCOVERY_TIME.astype(float)\n",
    "\n",
    "#data.FIRE_SIZE = data.FIRE_SIZE.astype(float)\n",
    "data.FIRE_SIZE_CLASS = data.FIRE_SIZE_CLASS.astype('category')\n",
    "#data.LATITUDE = data.LATITUDE.astype(float)\n",
    "#data.LONGITUDE = data.LONGITUDE.astype(float)\n",
    "data.OWNER_DESCR = data.OWNER_DESCR.astype('category')\n",
    "data.STATE = data.STATE.astype('category')\n",
    "data.DISCOVERY_MONTH = data.DISCOVERY_MONTH.astype(float)\n",
    "\n",
    "def convert_days_int(df_column):\n",
    "    day_numbers=[]\n",
    "    for day in df_column:  #converting categorical ordinal Strings correctly to ints\n",
    "        if day=='Monday':#values 0-6, so Monday=0\n",
    "            day_numbers.append('0')\n",
    "        elif day=='Tuesday':\n",
    "            day_numbers.append('1')\n",
    "        elif day=='Wednesday':\n",
    "            day_numbers.append('2')\n",
    "        elif day=='Thursday':\n",
    "            day_numbers.append('3')\n",
    "        elif day=='Friday':\n",
    "            day_numbers.append('4')\n",
    "        elif day=='Saturday':\n",
    "            day_numbers.append('5')\n",
    "        else:  #previously we have seen that there are none missing, so no need for another case\n",
    "            day_numbers.append('6')\n",
    "    return day_numbers\n",
    "\n",
    "data.DISCOVERY_DAY_OF_WEEK = convert_days_int(data.DISCOVERY_DAY_OF_WEEK)\n",
    "data.DISCOVERY_DAY_OF_WEEK = data.DISCOVERY_DAY_OF_WEEK.astype(float)\n",
    "\n",
    "cause_cat=[]\n",
    "for row in data.STAT_CAUSE_DESCR:\n",
    "    if row in ['Debris Burning', 'Arson', 'Campfire', 'Children', 'Smoking']:\n",
    "        cause_cat.append('Human-direct')\n",
    "    else:\n",
    "        cause_cat.append('Natural/Human-indirect')\n",
    "\n",
    "data['CAUSE_CATEGORY'] = cause_cat\n",
    "data.CAUSE_CATEGORY = data.CAUSE_CATEGORY.astype('category')\n",
    "data.drop(['STAT_CAUSE_DESCR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more than half of the fires, the owner of the land is unspecified, so it might be hard to infer this information - need to explore more. One-hot coding will likely help here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data.drop(['CAUSE_CATEGORY'], axis=1)\n",
    "targets=data['CAUSE_CATEGORY']\n",
    "#with shuffling, seed, for replicability\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.isnull().sum())\n",
    "print('train set size \\n',X_train.shape)\n",
    "print('\\n')\n",
    "#print(X_test.isnull().sum())\n",
    "#print('test set size \\n',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Majority class percentage\n",
    "y_train.values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values - only after splitting\n",
    "#Might want to test dropping instances with missing values from train set - need to explore effect on result\n",
    "#Fill missing values with median values instead of deleting instances\n",
    "#Might be a good idea to look at distributions\n",
    "\n",
    "#Preprocessing pipeline\n",
    "#For trees, forests only missing value handling and categorical conversion to one-hot-coding applies\n",
    "\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xcols = X[self.cols]\n",
    "        return Xcols\n",
    "\n",
    "class DFFeatureUnion(TransformerMixin):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        return Xunion\n",
    "\n",
    "\n",
    "class DFImputer(TransformerMixin):\n",
    "    # Imputer but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, strategy='mean'):\n",
    "        self.strategy = strategy\n",
    "        self.imp = None\n",
    "        self.statistics_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imp = Imputer(strategy=self.strategy)\n",
    "        self.imp.fit(X)\n",
    "        self.statistics_ = pd.Series(self.imp.statistics_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Ximp = self.imp.transform(X)\n",
    "        Xfilled = pd.DataFrame(Ximp, index=X.index, columns=X.columns)\n",
    "        return Xfilled\n",
    "\n",
    "\n",
    "class DFStandardScaler(TransformerMixin):\n",
    "    # StandardScaler but for pandas DataFrames\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ss = None\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.ss = StandardScaler()\n",
    "        self.ss.fit(X)\n",
    "        self.mean_ = pd.Series(self.ss.mean_, index=X.columns)\n",
    "        self.scale_ = pd.Series(self.ss.scale_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xss = self.ss.transform(X)\n",
    "        Xscaled = pd.DataFrame(Xss, index=X.index, columns=X.columns)\n",
    "        return Xscaled\n",
    "    \n",
    "class DFRobustScaler(TransformerMixin):\n",
    "    # RobustScaler but for pandas DataFrames\n",
    "\n",
    "    def __init__(self):\n",
    "        self.rs = None\n",
    "        self.center_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.rs = RobustScaler()\n",
    "        self.rs.fit(X)\n",
    "        self.center_ = pd.Series(self.rs.center_, index=X.columns)\n",
    "        self.scale_ = pd.Series(self.rs.scale_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xrs = self.rs.transform(X)\n",
    "        Xscaled = pd.DataFrame(Xrs, index=X.index, columns=X.columns)\n",
    "        return Xscaled\n",
    "    \n",
    "class Log1pTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xlog = np.log1p(X)\n",
    "        return Xlog\n",
    "    \n",
    "class DummyTransformer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dv = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # assumes all columns of X are strings\n",
    "        Xdict = X.to_dict('records')\n",
    "        self.dv = DictVectorizer(sparse=False)\n",
    "        self.dv.fit(Xdict)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xdict = X.to_dict('records')\n",
    "        Xt = self.dv.transform(Xdict)\n",
    "        cols = self.dv.get_feature_names()\n",
    "        Xdum = pd.DataFrame(Xt, index=X.index, columns=cols)\n",
    "        # drop column indicating NaNs\n",
    "        nan_cols = [c for c in cols if '=' not in c]\n",
    "        Xdum = Xdum.drop(nan_cols, axis=1)\n",
    "        return Xdum\n",
    "\n",
    "cat_features=['FIRE_SIZE_CLASS','OWNER_DESCR','STATE']\n",
    "num_features=['FIRE_YEAR','DISCOVERY_DOY','DISCOVERY_TIME','LATITUDE','LONGITUDE','DISCOVERY_MONTH','DISCOVERY_DAY_OF_WEEK']\n",
    "num_features_log=['DURATION_MINUTES', 'FIRE_SIZE']\n",
    "\n",
    "#pipeline = make_pipeline(DFFeatureUnion([(make_pipeline(ColumnExtractor(cat_features),DummyTransformer())), (make_pipeline(ColumnExtractor(num_features),DFImputer(strategy='median')))]))\n",
    "pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(cat_features)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(num_features)),\n",
    "            ('imputer', DFImputer(strategy='median'))\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(num_features_log)),\n",
    "            ('imputer', DFImputer(strategy='median')),\n",
    "            ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proc=pipeline.fit_transform(X_train)\n",
    "#x_proc.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_proc.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_proc.isnull().sum())\n",
    "#print('\\n')\n",
    "#print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(['DURATION_MINUTES','FIRE_SIZE'], axis=1).plot(kind='box', figsize=(15,15))\n",
    "cat_features=['FIRE_SIZE_CLASS','OWNER_DESCR','STATE']\n",
    "num_features=['FIRE_YEAR','DISCOVERY_DOY','DISCOVERY_TIME','LATITUDE','LONGITUDE','DISCOVERY_MONTH','DISCOVERY_DAY_OF_WEEK','DURATION_MINUTES', 'FIRE_SIZE']\n",
    "\n",
    "x_proc[num_features].plot(kind='box', figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of outliers with duration, fire size - try log transform, maybe cap duration, as the furthest ones appear to be errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['CAUSE_CATEGORY'].value_counts().plot(kind='bar',color='red')\n",
    "#plt.show()\n",
    "#Noticable imbalance, but better than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['DISCOVERY_DAY_OF_WEEK'].value_counts().plot(kind='bar',color='red')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['STATE'].value_counts().head(n=10).plot(kind='bar',color='red')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation matrix**\n",
    "\n",
    "Only for numerical values, doesn't make much sense to correlate non-ordinal categorical features (e.g. state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_corr(df,size=15):\n",
    "#    corr = df.corr()  #the default method is pearson\n",
    "#    fig, ax = plt.subplots(figsize=(size, size))\n",
    "#    ax.matshow(corr,cmap=plt.cm.Reds)\n",
    "#    plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "#    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "#    for tick in ax.get_xticklabels():\n",
    "#        tick.set_rotation(45)    \n",
    "#    plt.show()\n",
    "\n",
    "#plot_corr(x_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Here's how to get data ready for fitting models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=pipeline.fit_transform(X_train)\n",
    "trainy=y_train.cat.codes\n",
    "\n",
    "testx=pipeline.transform(X_test)\n",
    "testy=y_test.cat.codes\n",
    "\n",
    "#From here it should be straighforward to fit initial models for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive feature elimination\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "fe_tree = DecisionTreeClassifier()\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "rfecv = RFECV(estimator=fe_tree, step=1, scoring='accuracy', verbose=1, n_jobs=-1, cv=10)\n",
    "rfecv.fit(trainx[:10000], trainy[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (no of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='red')\n",
    "plt.show()\n",
    "#Since there is no significant increase in performance with using more than ~40 features, \n",
    "#take those top 40, which may facilitate simpler model, which may generalize better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch for hyperparameters\n",
    "tree_pipeline=make_pipeline(DecisionTreeClassifier())\n",
    "tree_pipeline.named_steps.keys()\n",
    "tree_params=dict(decisiontreeclassifier__criterion=['entropy','gini'], decisiontreeclassifier__max_depth=[15,17,20,22,25])\n",
    "tree_grid_search=GridSearchCV(estimator=tree_pipeline, param_grid=tree_params, verbose=1, n_jobs=-1, cv=5)\n",
    "tree_grid_search.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_pipeline=make_pipeline(RandomForestClassifier())\n",
    "forrest_pipeline.named_steps.keys()\n",
    "forrest_params=dict(randomforestclassifier__n_estimators=[30,35], randomforestclassifier__max_depth=[25,30,35])\n",
    "forrest_grid_search=GridSearchCV(estimator=forrest_pipeline, param_grid=forrest_params, verbose=1, n_jobs=-1, cv=5)\n",
    "forrest_grid_search.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=17)\n",
    "tree.fit(trainx, trainy)\n",
    "tree_test_predicted = tree.predict(testx)\n",
    "\n",
    "print('Decision tree accuracy: ', accuracy_score(testy, tree_test_predicted))\n",
    "\n",
    "tree_train_predicted = tree.predict(trainx)\n",
    "print('Decision tree train accuracy: ', accuracy_score(trainy, tree_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predicted=tree.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testy.values\n",
    "#y=testy.ravel()\n",
    "#testy.ravel()[1]\n",
    "#y_predicted[1]\n",
    "#y_predicted= tree.predict_proba(testx)\n",
    "#y_predicted[:,1]\n",
    "#testy.values\n",
    "#testy[:10].values\n",
    "#y_predicted[:10,1]\n",
    "#targets.shape[0]\n",
    "#testy[:10].values\n",
    "#testy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predicted= tree.predict_proba(testx)\n",
    "n_classes=3\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(testy.values, tree_predicted[:,1])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw/2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest = RandomForestClassifier(max_depth=30, n_estimators=70, max_features=40)\n",
    "forrest.fit(trainx, trainy)\n",
    "forrest_test_predicted = forrest.predict(testx)\n",
    "\n",
    "print('Random forest accuracy: ', accuracy_score(testy, forrest_test_predicted))\n",
    "\n",
    "forrest_train_predicted = forrest.predict(trainx)\n",
    "print('Random forest train accuracy: ', accuracy_score(trainy, forrest_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_predicted= forrest.predict_proba(testx)\n",
    "n_classes=3\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(testy.values, forrest_predicted[:,1])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw/2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define confusion matrix function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_predictions=forrest.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predictions=tree.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['Direct','Natural/ Indirect']\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "forrest_cnf_matrix = confusion_matrix(testy.values, forrest_predictions)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(forrest_cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "tree_cnf_matrix = confusion_matrix(testy.values, tree_predictions)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(tree_cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tree = DecisionTreeClassifier()\n",
    "basic_tree.fit(trainx, trainy)\n",
    "basic_tree_test_predicted = basic_tree.predict(testx)\n",
    "\n",
    "print('Decision tree accuracy: ', accuracy_score(testy, basic_tree_test_predicted))\n",
    "\n",
    "basic_tree_train_predicted = basic_tree.predict(trainx)\n",
    "print('Decision tree train accuracy: ', accuracy_score(trainy,basic_tree_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tree_scores = cross_val_score(basic_tree, trainx, trainy, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "tree_scores = cross_val_score(tree, trainx, trainy, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "forrest_scores = cross_val_score(forrest, trainx, trainy, cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross validation accuracy scores:')\n",
    "print('Tree with default hyperparameters')\n",
    "print(basic_tree_scores.tolist())\n",
    "print('Tree with tuned hyperparameters')\n",
    "print(tree_scores.tolist())\n",
    "print('Random forest with tuned hyperparameters')\n",
    "print(forrest_scores.tolist())\n",
    "print('')\n",
    "print(\"95% confidence intervals:\")\n",
    "print(\"Basic tree accuracy: %0.5f (+/- %2f), stdev=%f\" % (basic_tree_scores.mean(), basic_tree_scores.std() * 2, stdev(basic_tree_scores)))\n",
    "print(\"Tree accuracy: %0.5f (+/- %2f), stdev=%f\" % (tree_scores.mean(), tree_scores.std() * 2, stdev(tree_scores)))\n",
    "print(\"Forrest accuracy: %0.5f (+/- %2f), stdev=%f\" % (forrest_scores.mean(), forrest_scores.std() * 2, stdev(forrest_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Claims:\n",
    "#1 (tuned) tree accuracy mean>basic_tree accuracy mean\n",
    "#2 Forrest accuracy mean>tree accuracy mean\n",
    "# take alpha the significance level=0.01\n",
    "\n",
    "print(ttest_rel(tree_scores,basic_tree_scores).pvalue/2)\n",
    "print(ttest_rel(forrest_scores,tree_scores).pvalue/2)\n",
    "\n",
    "print(ttest_rel(tree_scores,basic_tree_scores))\n",
    "print(ttest_rel(forrest_scores,tree_scores))\n",
    "print('Since t>0 and p/2 < alpha, in both cases the null hypotheses are rejected (the null hypotheses are that mean value of differences is 0), so we accept the alternative hypotheses, which are the original claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy bars with confidence error bars\n",
    "N = 3\n",
    "means = (basic_tree_scores.mean(), tree_scores.mean(), forrest_scores.mean())\n",
    "errs = (basic_tree_scores.std()*2, tree_scores.std()*2, forrest_scores.std()*2)\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, means, width, color='r', yerr=errs)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Scores by models with 95% confidence interval error bars')\n",
    "ax.set_xticks(ind )\n",
    "ax.set_xticklabels(('Tree default', 'Tree tuned hyp.', 'Random forrest'))\n",
    "ax.set_ylim(0.724,0.802)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy bars with confidence error bars\n",
    "N = 3\n",
    "means = (basic_tree_scores.mean(), tree_scores.mean(), forrest_scores.mean())\n",
    "errs = (basic_tree_scores.std(), tree_scores.std(), forrest_scores.std())\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, means, width, color='r', yerr=errs)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Scores by models with standard deviation error bars')\n",
    "ax.set_xticks(ind )\n",
    "ax.set_xticklabels(('Tree default', 'Tree tuned hyp.', 'Random forrest'))\n",
    "ax.set_ylim(0.724,0.802)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
